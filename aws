AMazon.com, netflix 
Region is cluster of DC's and most services regional scope,, az- min2/6 - usual 3, azs superate for dr and ntwrk connected
choosing: compliance, proximity, available services, pricing
2 types of services global/regional

IAM: user - group -ploicy (JSON),, least privilage prinnciple,, group onley user not group,, permission inheritance. console login/access key
policy- versio,id,statement{sid, effect(allow),principle(acount assign), actions,resource,condition}
user security-- password policy, MFA (password + taken in the mobile - user -security credentials - mfa) 
MFA : virtual MFA (google authenticator, authy),,universal 2nd factor u2f: physical, 3rd party, multi root ac support,, hardware key fab(gemalto) for aws gov cloud 
password policy: user account settings-pwd policy,, min max length, upper, aplhanumneric, expireation, reuise , user own change
access key: cli,sdk(sdk,mobile sdk,iot device sdk), generate by user, user- generate access key  ,, only one time download, multiple create (key id/secret key get)
commad line: aws cli (nearest region )/ cloud shell(default region) - both need proper permission for acs
ROLES:for services-ec2,asg,lb,sqs,sns/**security tool1>credentials report(acnt)-details about user account 2>acess advaisor(user activity- analyse fr least priviliged)

EC2:cap:running vm,storing data with ebs/efs, distributing load(LB), scaling automatic(ASG),, every ec2 has os,cpu,ram, nwk, hardware (instance store),firewall(SG),
ntwk card, bootstrap script (user data - first startup for sftwr inslltions **will run with root only)
types:1>GEneral perpose: dicersity of work load balance for compute,memory and network - m,t series) 2> compute optized: high performance proceesor(batch process, 
media transcoding,hpc,scintific,ml,gaimg servers - c series) 3> memory optimized: process large set of mem: 1> high performdb, webscale cacje,inmemory db,
real time process of big unstructured data- R and x series) 4>storage - high for read and write for local storage) - oltp (online transaction processing), 
relational and no sql, cache for in memory db redis, distributed fs - i and d series)

SG: firewall on ec2, only allow rules, refer by ip or sg,, superate for inbound and outbound)(protocal,tcp/udp/http, port range,source), work as firewall
one sg to many svcs,**locked down to vpc or region,, sg is out side of ec2, good to sup sg for ssh, all inbound blocked all outbound allowd by default,
sg isues time out and not accessible/ non sg related : connection refused,not launched,, sg can allow multiple sg as inbound,, used to control incoming trafic 

ssh: default user, ssh -i public.key  ec2user@public ip for lap pvt ip for infra, 0400 permissions
ssh issues: 1>connection time: sg issues if still issue with company or prsnl firewall 2> connection refused: restart 3>permission denied : key issues
4> work befire not wrkng now: check the publicp if ec2 rebooted

ec2 instance role: use case: to use aws cli we have to give userid/pwd not safe so execute aws cli from an ec2 and assign proper roles for that ec2 to avoid credentials config

PURCHASING OPTIONS: 1> on demand: short workload and predictable pricing 2>Reserved: long workload like db, can covert instacne type , scheduled long work load everyday
3>Spot instance 4>Dedicated host,,,1>dedicated: pay per second(linux,windows) pay per hour for other, no upfront payment, no interupt 2> REserved: *75% discount **1-3 year 
no upfront, partial, full (more dscount) supports schedulable evry day for 1 hr like,3>Spot:*90%,*spot+ondemand, not for critical, max proce < spot prize, price change frqntly
if pice < spot 2 things stop or trminate4>dedicated host (physical server with ec2 capacity): *3 year, own licence and compliance usage, more expensive 4.1>dedicated host(instance 
running on hardware dedicate, after restart can place on other hardware)

IP's:public ip:can be identified on internet, uniques in www, geo-lated easily, private:uniques in private nwk,2 df pvt nwk has same ip,,elastic ip:fixed ip ipv4,chargable after allocation

ec2 placement groups: 1.cluster: single az, low latency, high perfor and risk,2>Spread:across az 7 per az.ha,3>Partition:7 partitions(rack) per az,100 limit,ha

ENI:1 public ip, 1 private ip, i elastic ip, 1 r more sg, 1 mac addr**az bound, easily  reasing to other ec2 helpfull in dr to have same ip

EC2 Hibernate: in memory ram is stored to root ebs with encrypted,os boot is high speed,**ebs is root and ram <150gb,**linux,ubunut ami**ondemand and reserved*must encrypt ebs*c,m,r series
ec2 nitro: advanced version, hish speed 64k ipos 2 time for normal, vcpu: thread in main cpu, can optimize the vcpu at launch time based upon perf

EBS: ntwrk drive so bit latency can attach to one ec2 at a time, persist after termination for root volume ebs (default), esb nwtrk stcks, can move acress ec2 in failurs,**bound to az 
for other az create snap shot and copy to other az,**30gb general purpose free storage per mnth, *efault destroy after ec2 terminationcan change, provison in 2 ways size and iops 
ebs snap shot we can take at any point of time, not neceesary to detach but good practise,, 

EC2 Instance store: hard drive attached from the hardware where ec2 hosted,, very high speed, *ephermal: lost if ec2 down, good for cache,buffer,,exam: high performance storage
AMI: Amazon machine image, contain os,config,softwares,,aws has default we can customise them,,**bound to a specific region can copy to others types public/own/market place,, 

EBS volume types:1>gp1/gp2 ssd,10 gb increase if disk low,root,3000 ips/max 16000,1gb to 16tb 2>io1/io2 ssd, 4gb-16tb, 32k iops/ for nitro 64k ipos, app need >16k iops this good, 
esb multi attach,3>st1/sc1 500mb-500iops/250mb-250 iops big data,log process/infrequent acess ,lowest cost
EBS multi attach: one to many ec2 with read and write, io1/io2,,encryption with kms: data at rest, inflight, snapshot, volumes by ebs..low latency,,2 ways 1>create snap,encrypt and restore 
2>while creating volume enable encrypt

EFS: ntwrk fs, one to many,*multi az,posix fs fr linux only, data sharing and web serving, auto scaling pay per use,3 mondes 1>performance(general,max io)2>Throughput(bursting1tb/50-100mbps/
provison-1tb-igbps)3>storage(standerd-for frequent,infrequent access-cost to retrive,lower cost to storage)-mount 1>dns2>ip>dns-install amazon util lib,create fs and mount,add nfs in sg

LB: single point od dns, handle failures of down stream,health check,ssl,sticky ness, ha in multi az, superate private and public traffic>ELB is aws managed for ec2,ecs,asg,route 53,waf
types 4 clb,ALB,NLB,GLB,, 1>CLB: tcp(layer4),https/s(layer7),fixed host name 2>ALB:http,websocket,multi apps through TG,redirects, routing table on url,ip,query string, app srvr no idea 
of user ip,400ms latency, x-forwarded-for, x-forward-port,x-forward-prot),,3>NLB:layer4,100ms latencr, *one static ip for az support elastic ip, can send to ec2, ip private, alb




use lauch configuration/template, to update give new launch config/template,,free price for backend servers, iam on asg work for backen, if ec2 get temnited fr any reaon
ASG will recreate, replace instance marked unhealthy by LB. 
Scaling policies: 2 types 1>Dynamic 2>Predective: 1>Dynamic scaling: 1.1> Target tracking: if avg cpu > 40% increase 1.2>simple/step :can create own cloudwatch alarm and 
rules like if cpu >80 add 2 ec2 and cpu < 60 remove 2 instnaces can define cloud watch metrics 1.3>schedules:known usage 2>Provisioning:forecast & analysis by asg
ASG cooldown period:after scaling activity cooldown will come, no launch and terminate in this to stabilize metrics,,def 300sec, low cool hig perf, use golden ami for dis
ASG termination policy: default: find az with n number of instance, and inside it delete the oldest version means first created, balance instance in az,s along versions
ASG lifecycle hooks: p.wait,p.proceed,t.wait,t.proceed,, launch  config vs template: template is old not reusable need recreate, config: partial reusable, ondeamand or
spor or both, recomnded by aws,, both allows ami in confiuration
RDS: Relational db service : svc manage by aws for db, use sql, types: postgresql, mariadb, mysql, oracle,microsoft sql, use: auto provison,patching,bckp and restoere
point of time recovery, monitering,read replica, multi az, maintainance wid,auto scal vertical and horizontal,backedebs gp2/3,cant ssh
Automated backup: daily full bkp in maintainace by aws, transacton logs 5 mins, point oftime recovery(old to 5 mins),7 days retentionsnap shot: manually by user, alive
until delete,USE:backup specific time,RDS auto scaling: for max storage thresold, rules:storage<10%,low storage for 5mins,no transaction in 6 hours,unexpcted load,all dbs
Read replicas: 5, for read scale,async eventually consist, update app with all read replica urls, for selectquery only,use: to read db for analysis reporting tools.pay fr
cross region replicasntwrk no pay fr sameregion,RDS multiaz:DR,stand by in sameregion,write same time,same dns no trouble forapp, autofailover nt scaling,read replicas
can set as this,how multiaz work:snaptaken,restore in new az,enable sync..RDS encryption: both master and RR with KMS-AES256,at launchtime, if master not RR not encrypt,
another way TDE(transperant data encrypt),in flight by ssl,force users for this,postgres(rds_force_ssl=1),my sql update with in db, how to encrypt unencrypted rr- restore
db from it and enableencrypt at launch, SECURITY: ntwrk sec: put in pvt sbnt, iam policy for users managing db,, IAM authentication by iam and rds api calls, sql and 
postgres only,auth token 15 mins, 

AURORA: not open source, postgress and mysql, 5x on mysql and 3x on postgresof rds, storege autoscale in 10gb and max 128tb, 15 replicas, 20%> rds price,
self healing apps peer to peer if something bad, storge stripped into small pieces, one master for writes and remain reads, master + 15 rr in multi az, write has 
writer end point url and reader has reader end point only one for all rr actsa as LB,if master fails one of rr turn into master in 30 sec with same writer end point,
reagonal cluster= write + read endpoint sec smae as rds,, Features: 1>autoscaling: aurora can monitor read req and increase replicas.2>custom end point:some subset of rr
for analytical quaries, if this avail no use for read endpoint 3>Serverless:automated installation, scaling and pay per sec based on usage,cost effecive, no capaity plan
generate proxy by aws to connect to aurora, 4>Multi master: immediate failover,every node has read and write asno promote rr as master, 5> Auroraglobaldb: cross 
regionreplica, 1 primery region and 5 secondary regions, 16 rr across these, latency < 1 sec, rto9recovery time object at DR)< 1 min, for global applications
6>Machine learning:mlbased predicton, integration b/w aurora and aws ml sevces, support: amzon sega maker and comprehend use: fraud detect, prdct recomndtion,ads trgeting

Elastic cache: redis&mem-cached, in memory db, highperf, lowlatency, reduce to db for common quaries, app ned heavy changes, aws can manage this fully for operations
redis: multi az/rr/persistance/backup&restore Memcached: multi node(sharding),multi threaded, nopersistant,restore & backup
Securiyt: IAM roles for only creae and delete cache not for the data inside cache, Redis auth: user/pwd while creating db will used inside app, ssl, memcached-sasl auth
types of caching: 1>lazy: some stale data,2> Write through: when db updates cache update no stale data3>session store: session data using ttl:: USE_CASE: leader boards
in gaming sites as redis sorted set : unique and element ordering new order for new element:PORTS:postgres:5432/mysql:3306/oracle:1521/Mssql:1433/Maria:3306/aurora:5432

DNS: domain name system:convert host name into backend ip, terminology: domain registrer (ca), domain record:a,aaaa,cname,alias zonefile: dns record ,name server:quaries
(authorative/non autherative)-TLD-.com.in.us.gov,SLD-second amazon.com, 
flow--> web server --> local dns by org/cache iv ip to --> root dns give ip to--> TLD --> SLD --> here it will send the browser the actual ip of the service

Route 53: managed,scalable,authorative(user can maintain dns recordds), is domain register gie certs, health check of resources,100% availability sla,port 53 for dns
RECORD: contains domain or sub domain name/request type (A or AAAA or  CNAME or Alias)/value/Routing policy/TTL,, 
A: Maps a host name to ipv4,,AAAA: maps ahost name toipv6,,CNAME: maps a host name to another host name and dest ost name is eiter a or aaaa record,, and can't be a 
root domain ALIAS:is same as root domain only but can also use root,,,Alias: work for root and non root, health check,auto recginise backend ip changes, suported 
backends: elb, cloudfront,api,ebs,s3,vpe end points,oter r53 record in same hosted zone,global accelerator
NS(naming serer):for hosted zone contain dns name and ip can respond to quaies for trafic route
Hosted Zone: contain record that how to rout traffic,2 public (internet)and private(vpc), $0.50 per month
**Nslookup ordig cmds for lburl tosee the backend ips, TTL: time to leave, attach in client responce along public ip,2 high,low..High: less trafic for r53 but old data
Les: More traffic for r53 less ooutdated,must for all record type not ALIAS, dig command to see ttl
ROTING POLICY: simple,weighted,failover,latency based,geolocation,geo proximity,multi-value,, SIMPLE: tosingleresource, multiple values can,send to client, best chosen
by client, Weighted: control % trafic to speciic resource,backend dns have same name and type, health checks,use: LB b/w regiosn, test new ap fr less trafic, weight 
zero to stop sending, or 0 for all to sent trafic equally,,LATENCY: route to low latency instances, b/w user and aws region,health cheks,FAIL OVER: like dr, 1 primary 
1 secondary, primary not go for secondary,based on health check,,GEO LOCATION: Depends on location of user, if user in us go this ip,if in german go thi,default record
use: content loca,restrict in country,load balance,, health checks,,GEO PROXIMITY: baesd on geographic location, biasing,less-low, high-more,, traffic flow must(UI)
Multi Value: routing to multiple resources/values, health check, 8 health record returned for each value, only healthy records, use dig to check ip's, 
Health Checks: only for public resources, 3 ways of monitering,1>metric 2>Health check3>cloud moitering,, health check will have their own metrics and integrate with 
cloud wathc metric, 15 health check check end point, threshold is 3, 30se reguler check,10 sec higher,support https/s,tcp pass code 2xx or 3xx or 1st 5120 bytes data
CAlculated health check: check multiple checks, user or,and,not operator,256chaild health check,define how many chaild health check, for private use cloudwath metric
3rd party domain: aws can maintain 3rd party domains, create hosted zone and add ns server to 3rd party, go dady will search for aws r53 by ns server
HA: Route 53 + ELB + ASG + multi AZ
Quick instance launching: Golden AMI/bootstraping/Golden AMI + boot straping(hybrid) can have rds db, esb..etc
EBS(elastic bean stalk)auto provisioning,load balancing,instance config.go,java,.net,php.etc

AWS S3: Infinay scaling storage, object stored in bucket, globaly unique name, **s3 is global level and bucket is regional level, key/value - path/file, max 5tb(5kgb)
if >5tb multi part upload, object have meta data,upto 10 tags,versioning,, how to open file in s3 2 from aws console open(presigned)/public access link,versioning at
bucket level, version come for new files, for old files version is null, use: unintended delte,rollback,, suspending version dont delete previous files,d/f version id 
for every upload,delete marker- file is not available but older versions are there,can delete this if needed,
S3-Encryption: SSE-S3/SSE-KMS/SSE-C/Client side> 1>SSE-S3:serverside,aes-256,header x-amz-server-side-ecryption:aes-256,key own by AWS,2>SSE-KMS: server side, key
maintained by kms,header sert to awskms,use:user control + audit on key 3>SSE-C:key maintain by user,sent in https header for all request,same key for decrypt, https 
traffic to s3 4>Client side encruption: user encrypt/decrypt data before s3,, Encypt intranstion:s3 have 2 ends http/https any thing can ue: https sure for sse-C

S3 security: user based: IAM policy to control api calls on s3, resource based: bucket side rules,define principles,object and bucket acl (access control list)
if iam policy permission accept, reource policy allo itno explicit deny rule
s3 bucket policy:jsone;same format as iam policy, version,id,statement,sid,effect,principal,action,resources,use: grant public access,force object to encrypt at upload
grat access to other account,, logging and audit: s3 access logs can stord in other buckett, api calls can be logged in aws cloud trail,, user security: MFA delete, 
presigned url: temporary url for limited time,,for 403 check public access and policies
S3-CORS: (cross origin resource sharng)- getting resources fro different origin, to allows thos cors headers eg: access-control-allow-origin,, allow oother origins
IAM policy simulator to test the policy,, ec2 instance metada: http://169.254.169.254/latest/meta-data,,aws-sdk control aws from app,, mfa needed for delete and suspend
versioning, not for enable version, bucket owner or root can enable/disable MFA,,s3 encryption 2 ways: hw to force: s3 policy condition,default encryption(dont do for
already encrypted ones)--access logs: all requestt details accept,deny,action, athen to analyse,**never make logging bucket same bcome loop,,

S3 replication: CRR/SRR/different acnt, must versining, asynchronus copy, must properr iam perission,not retro active only new objet will replicate,for delete 2 options 
replicate/non replicate for malicious deletes,no chaining one to one relation,
S3 presigned url: sdk and cli, download(cli) upload (sdk and hard), 3600 sec r set --expires-in time,inherit permisn of user granting,use:temporar acess,
Storage classes: standers,stander-IA,onezone-IA,intelligent tiering,glacier,lacier deep archive,reduced redundancey storage(depricated)
1>S3 standerd:high durability,availability 99.99,sustainn 2 concurrent fails for DR, 2>S3 Standerd IA: less frequently,availability&durability-99.99,low cost,2 failure
3>s3 one zone ia: single az,low latency, support ssl, 20% cost < IA, use :store second bkp,thumbnails4>Intelligent tiering: monitering monthy,auto-tiering fee,auto_
matically moves,5> Glacier or vault: for archives/backups,long term 10 years, dur 99.99, per mnth $0.004/GB, stored in vaults,retrival 3 options: expidiated (1-5msn),
standerd (3 to 5),bulk(5 to 12 hrs),, min time 90 days,, 6>Glacier depp archives: more long time, more cheaper, retrival: standerd:12 hrs, bulk 48 hrs, ** for glacier 
we can't see them unless we retrive it, S3 Lfecycle: 1>transaction action: just move, move object to ia after 60days,move to glaicer after 6 months 2>Expiration actions
:for delete after some time use: log files delete, partial upload,old version,,rules can be applied specific path or object,,
S3 Anlytc: to help lifycycle transaction rules, not onezone-ia, report daily,24 to 48 fr 1st start,, multi upload, prefer >100mb, must >5gb, help parllel upload
S3 Tranfer acceleration: increase speed as file- aws edge near- s3 bucket,,s3 byte range fetch: can download small parts of download,speedup,to download some part file
S3 select & glacier select: retrive less data by perform serverside quaries, fast and quick,, S3 Event notifications: action at s3 like create, remove, relicated,
delete object. can create rules, use sns,sqs or lambda,many events support, if 2 simultanius updates for non-version s3 only one evne trigger, if need exact events
then we need versioning enablesd, S3REQUESTOR PAYS: for data transfer requester pay for ntwrk cost but authorised user,,ATHENA: serverless query for s3,sql,$5 for tb
support csv,json,orc,,use compressed orcolumn data cost save,,business intelligence,report,anlyse,vpc flow logs,cloud trails,,Glacier vault lock:adopt WORM(write 
once read many),objct and lock can't be delete,, OBJECT lock: must versioning,WORM,block delete for some retention time 2 type: rentention period: some time 2>Legal 
hold: no psecific time Modes: governance mode: cant alter or delete objct, compliance mode: can't alter rootention mode even root

AWS CLOUD fRONT: CDN (content delivery network) improcve read perf, caching,216 edge globaly,DDOS protection,integrate with shield and WAF, reduce load on s3,
Origins: s3(sec with OAI -orign access only, ingress to upload to s3),alb allow sg of public ip fr edge locations,ec2,s,any http backend,,
GEO Restriction: white list: allow useres if they are in speciic country, black list: deny access if they are in specific countires,,use : copyright laws
cloud front vs s3 cross region replication: CDN: cachce and static data,S3 cross:fr dynamic data near real time,, signed url: temporary access, URL expiration + cookie,
ip range to allw,trusted signers,uses: shared and private content..signed url:access to individual files,, signed cookies: aaccess to multiple files 
cloud front signed url vs s3 presigned url: cdn:acces to any path filters for ip,pat &caching&root only mainina,,s3:IAM users, no filters,inherits url created permissions
prcing: edges are global, price varies from region, reduce no of edge for cost saving,, Multi origins: DR, 1 primary and 1 secondary, Field level encryption: data is
encrypted at edge location with public key, can do for specific fields of data in one post, addition sec than https,,
GLOBAL ACCELERATOR: send trafic in aws network instead of public, unicat/anycast ip: unicast ip: one service one ip, any cast: all services one ip, global accelerator 
uses any cast ip,2 anycast ip, dircet to dge location,great for dr, helath checks < 1 mins unhealty, sec: only 2 ips can be witelisted, work as proxy at edge fr sercs
Global accelerator  vs cloud front: Global: non http nd htpp, no cahce, app with satic ip,fast regional failover CDN: integrate with shield for ddos, caching

SNOW FAMILY: secure and portable devices collect and process and migrate data a t edge,,data migration:snow cane, snowball edge,snow mobil edge computing: cone and ball\
challeges for data migration: conectvity, bw,ntwrk cost,price, connection stability,, snow family: ofline devices in post,, SNOW BALL EDE: tbs & pbs, suprt block and s3
pay per data,2 type storage 80tb/compute otimized 40tb,us : cloud migratin,decom of dc, dr in aws,, SNOW CONE: small device,etheret,8tb,SNOW MOBILE: Truck, 100pb,
truck sec gps,vidoe survlencs 24/7,,edge computing: places with limited/no internate and computing power, aws ops hub: software for snowfamily suport clustering
snow cone: 2cpu,4 gb ram: snow ball edge storage: 52 cpu,20gb ram,42tb usable storage,,snowball edge copute: 40 vcpu,80gb ram

FSX: 3rd party fs by fsx, types: fsx for luster,windows,netapp ontap,directly launch at aws,,windows: smb, ntfs protocal,scale 10gb,ssd,onpremise also,daily bkp to s3, multi az
CLuster: luster, large scale, use: machine learning, hpc,, scale in 100gbs,sub mil latency, cont integration with s3, can write to s3 by fsx,on-premise also
types of fsx: sccratch file system: temporary,short term,6x faster than normal,200mbps per tb,2>persistant: lonng term,same az replica
Hybrid cloud: some part of infra on cloud and some on-premise use:migration,elastic only on cloud

Storage gateway: bridge bw s3 and on-prem use: DR, backups&restore, 3 types: file,volume,tape gateways,, can import either to ebs,s3,glacier
File Gateway: configured s3 buckets aceess by nfs and smb, support standers,ia,glacier,one zone ia,use iam roles,caching,integrates with AD
Volume Gateway:block storage, iscsi protocal backed by s3,ebs snap shots,2 types 1> cached volumes: low latency 2>stored volume: entire data on-premise and backup to s3
Tape Gateway: backup by tapes stored in cloud, vtl (virtual tape library), use iscsi protocal,,, * in all above 3 gws hardware is installed on client side if no hardware
available then aws will provide that "Storage gtway - hardware appliance" 
Exam questions: account/nfs with ad - file gateway,,volume/block storage : volume, tapes:tape , no onpremise virtual server: hardware
FSX gateway: access to fsx windows,cache,smb,nfts,ad,group file share or direecctory
AWS TRANSFER famialy: transfer files from in and out to s3 and efs using ftp , ptocals : ftp, ftps,sftp , multi az, pay per provisoin,integrates with ad and cognito,,

Integration and messaging:
-------------------------
Orchastrating stuff between different services using middleware, application communication 2 types: 1> Synchronus (application to application)2>Asynchronus (app to 
que to app),, synchronus: neg: sudden spikes for traffic, so we need to decouple the application by SQS(que),SNS(pub/sub),Kinesis(data strem),,scale independantly

SQS(simple qeueing service)?? Que contain messages, producer, consumer, send messages, poll messages, stabderd que, unlimited through put and messages in the ques,,
retention: min 4 days, 14 max days,, low latency, 256 kb per msg, can have duplicate mss at lease once delivery, out of order messages best effort ordeering 










